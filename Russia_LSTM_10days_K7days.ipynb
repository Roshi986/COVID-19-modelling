{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.compat.v1.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import ConvLSTM2D\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "countryName = 'Russia'\n",
    "\n",
    "nFeatures = 1\n",
    "\n",
    "nDaysMin = 10\n",
    "k = 7\n",
    "\n",
    "nValid = 10\n",
    "nTest = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = os.path.join('C:\\\\Users\\\\AMC\\\\Desktop\\\\Roshi\\\\Data')\n",
    "confirmedFilename = 'confirmed_july.csv'\n",
    "deathsFilename = 'deaths_july.csv'\n",
    "recoveredFilename = 'recovered_july.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed = pd.read_csv(confirmedFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>7/19/20</th>\n",
       "      <th>7/20/20</th>\n",
       "      <th>7/21/20</th>\n",
       "      <th>7/22/20</th>\n",
       "      <th>7/23/20</th>\n",
       "      <th>7/24/20</th>\n",
       "      <th>7/25/20</th>\n",
       "      <th>7/26/20</th>\n",
       "      <th>7/27/20</th>\n",
       "      <th>7/28/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>35475</td>\n",
       "      <td>35526</td>\n",
       "      <td>35615</td>\n",
       "      <td>35727</td>\n",
       "      <td>35928</td>\n",
       "      <td>35981</td>\n",
       "      <td>36036</td>\n",
       "      <td>36157</td>\n",
       "      <td>36263</td>\n",
       "      <td>36368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4090</td>\n",
       "      <td>4171</td>\n",
       "      <td>4290</td>\n",
       "      <td>4358</td>\n",
       "      <td>4466</td>\n",
       "      <td>4570</td>\n",
       "      <td>4637</td>\n",
       "      <td>4763</td>\n",
       "      <td>4880</td>\n",
       "      <td>4997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>23084</td>\n",
       "      <td>23691</td>\n",
       "      <td>24278</td>\n",
       "      <td>24872</td>\n",
       "      <td>25484</td>\n",
       "      <td>26159</td>\n",
       "      <td>26764</td>\n",
       "      <td>27357</td>\n",
       "      <td>27973</td>\n",
       "      <td>28615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.50630</td>\n",
       "      <td>1.521800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>880</td>\n",
       "      <td>884</td>\n",
       "      <td>884</td>\n",
       "      <td>889</td>\n",
       "      <td>889</td>\n",
       "      <td>897</td>\n",
       "      <td>897</td>\n",
       "      <td>897</td>\n",
       "      <td>907</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.20270</td>\n",
       "      <td>17.873900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>705</td>\n",
       "      <td>749</td>\n",
       "      <td>779</td>\n",
       "      <td>812</td>\n",
       "      <td>851</td>\n",
       "      <td>880</td>\n",
       "      <td>916</td>\n",
       "      <td>932</td>\n",
       "      <td>950</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
       "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
       "1            NaN        Albania  41.15330  20.168300        0        0   \n",
       "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
       "3            NaN        Andorra  42.50630   1.521800        0        0   \n",
       "4            NaN         Angola -11.20270  17.873900        0        0   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  7/19/20  7/20/20  7/21/20  \\\n",
       "0        0        0        0        0  ...    35475    35526    35615   \n",
       "1        0        0        0        0  ...     4090     4171     4290   \n",
       "2        0        0        0        0  ...    23084    23691    24278   \n",
       "3        0        0        0        0  ...      880      884      884   \n",
       "4        0        0        0        0  ...      705      749      779   \n",
       "\n",
       "   7/22/20  7/23/20  7/24/20  7/25/20  7/26/20  7/27/20  7/28/20  \n",
       "0    35727    35928    35981    36036    36157    36263    36368  \n",
       "1     4358     4466     4570     4637     4763     4880     4997  \n",
       "2    24872    25484    26159    26764    27357    27973    28615  \n",
       "3      889      889      897      897      897      907      907  \n",
       "4      812      851      880      916      932      950     1000  \n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confirmed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps, k):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix + k >= len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+k]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanAbsolutePercentageError(yTrueList, yPredList):\n",
    "    absErrorList = [np.abs(yTrue - yPred) for yTrue, yPred in zip(yTrueList, yPredList)]\n",
    "    absPcErrorList = [absError/yTrue for absError, yTrue in zip(absErrorList, yTrueList)]\n",
    "    MAPE = 100*np.mean(absPcErrorList)\n",
    "    return MAPE\n",
    "\n",
    "def meanAbsolutePercentageError_kDay(yTrueListList, yPredListList):\n",
    "    # Store true and predictions for day 1 in a list, day 2 in a list and so on\n",
    "    # Keep each list of these lists in a respective dict with key as day #\n",
    "    yTrueForDayK = {}\n",
    "    yPredForDayK = {}\n",
    "    for i in range(len(yTrueListList[0])):\n",
    "        yTrueForDayK[i] = []\n",
    "        yPredForDayK[i] = []\n",
    "    for yTrueList, yPredList in zip(yTrueListList, yPredListList):\n",
    "        for i in range(len(yTrueList)):\n",
    "            yTrueForDayK[i].append(yTrueList[i])\n",
    "            yPredForDayK[i].append(yPredList[i])\n",
    "            \n",
    "    # Get MAPE for each day in a list\n",
    "    MAPEList = []\n",
    "    for i in yTrueForDayK.keys():\n",
    "        MAPEList.append(meanAbsolutePercentageError(yTrueForDayK[i], yPredForDayK[i]))\n",
    "    return np.mean(MAPEList)\n",
    "\n",
    "def meanForecastError(yTrueList, yPredList):\n",
    "    forecastErrors = [yTrue - yPred for yTrue, yPred in zip(yTrueList, yPredList)]\n",
    "    MFE = np.mean(forecastErrors)\n",
    "    return MFE\n",
    "\n",
    "def meanAbsoluteError(yTrueList, yPredList):\n",
    "    absErrorList = [np.abs(yTrue - yPred) for yTrue, yPred in zip(yTrueList, yPredList)]\n",
    "    return np.mean(absErrorList)\n",
    "\n",
    "def meanSquaredError(yTrueList, yPredList):\n",
    "    sqErrorList = [np.square(yTrue - yPred) for yTrue, yPred in zip(yTrueList, yPredList)]\n",
    "    return np.mean(sqErrorList)\n",
    "\n",
    "def rootMeanSquaredError(yTrueList, yPredList):\n",
    "    return np.sqrt(meanSquaredError(yTrueList, yPredList))\n",
    "def medianSymmetricAccuracy(yTrueList, yPredList):\n",
    "    '''https://helda.helsinki.fi//bitstream/handle/10138/312261/2017SW001669.pdf?sequence=1'''\n",
    "    logAccRatioList = [np.abs(np.log(yPred/yTrue)) for yTrue, yPred in zip(yTrueList, yPredList)]\n",
    "    MdSA = 100*(np.exp(np.median(logAccRatioList))-1)\n",
    "    return MdSA\n",
    "\n",
    "def medianSymmetricAccuracy_kDay(yTrueListList, yPredListList):\n",
    "    # Store true and predictions for day 1 in a list, day 2 in a list and so on\n",
    "    # Keep each list of these lists in a respective dict with key as day #\n",
    "    yTrueForDayK = {}\n",
    "    yPredForDayK = {}\n",
    "    for i in range(len(yTrueListList[0])):\n",
    "        yTrueForDayK[i] = []\n",
    "        yPredForDayK[i] = []\n",
    "    for yTrueList, yPredList in zip(yTrueListList, yPredListList):\n",
    "        for i in range(len(yTrueList)):\n",
    "            yTrueForDayK[i].append(yTrueList[i])\n",
    "            yPredForDayK[i].append(yPredList[i])\n",
    "    # Get MdSA for each day in a list\n",
    "    MdSAList = []\n",
    "    for i in yTrueForDayK.keys():\n",
    "        MdSAList.append(medianSymmetricAccuracy(yTrueForDayK[i], yPredForDayK[i]))\n",
    "    return(np.mean(MdSAList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all three frames for a given country\n",
    "def getCountryCovidFrDict(countryName):\n",
    "    countryCovidFrDict = {}\n",
    "    for key in covidFrDict.keys():\n",
    "        dataFr = covidFrDict[key]\n",
    "        countryCovidFrDict[key] = dataFr[dataFr['Country/Region'] == countryName]\n",
    "    return countryCovidFrDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of data points for LSTM: 117\n",
      "Size of training set: 97\n",
      "Size of validation set: 10\n",
      "Size of test set: 10\n"
     ]
    }
   ],
   "source": [
    "# Load all 3 csv files\n",
    "covidFrDict = {}\n",
    "covidFrDict['confirmed'] = pd.read_csv(confirmedFilename)\n",
    "covidFrDict['deaths'] = pd.read_csv(deathsFilename)\n",
    "covidFrDict['recovered'] = pd.read_csv(recoveredFilename)\n",
    "\n",
    "countryCovidFrDict = getCountryCovidFrDict(countryName)\n",
    "\n",
    "# date list\n",
    "colNamesList = list(countryCovidFrDict['confirmed'])\n",
    "dateList = [colName for colName in colNamesList if '/20' in colName]\n",
    "dataList = [countryCovidFrDict['confirmed'][date].iloc[0] for date in dateList]\n",
    "dataDict = dict(zip(dateList, dataList))\n",
    "\n",
    "# Only take time series from where the cases were >100\n",
    "daysSince = 100\n",
    "nCasesGreaterDaysSinceList = []\n",
    "datesGreaterDaysSinceList = []\n",
    "\n",
    "for key in dataDict.keys():\n",
    "    if dataDict[key] > daysSince:\n",
    "        datesGreaterDaysSinceList.append(key)\n",
    "        nCasesGreaterDaysSinceList.append(dataDict[key])\n",
    "        \n",
    "XList, yList = split_sequence(nCasesGreaterDaysSinceList, nDaysMin, k)\n",
    "\n",
    "XTrainList = XList[0:len(XList)-(nValid + nTest)]\n",
    "XValidList = XList[len(XList)-(nValid+nTest):len(XList)-(nTest)]\n",
    "XTestList = XList[-nTest:]\n",
    "\n",
    "yTrain = yList[0:len(XList)-(nValid + nTest)]\n",
    "yValid = yList[len(XList)-(nValid+nTest):len(XList)-(nTest)]\n",
    "yTest = yList[-nTest:]\n",
    "print('Total size of data points for LSTM:', len(yList))\n",
    "print('Size of training set:', len(yTrain))\n",
    "print('Size of validation set:', len(yValid))\n",
    "print('Size of test set:', len(yTest))\n",
    "\n",
    "# Convert the list to matrix\n",
    "XTrain = XTrainList.reshape((XTrainList.shape[0], XTrainList.shape[1], nFeatures))\n",
    "XValid = XValidList.reshape((XValidList.shape[0], XValidList.shape[1], nFeatures))\n",
    "XTest = XTestList.reshape((XTestList.shape[0], XTestList.shape[1], nFeatures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nNeurons = 100 # number of neurones\n",
    "nFeatures = 1  # number of features\n",
    "\n",
    "bestValidMAPE = 100 # 100 validation for best MAPE\n",
    "bestSeed = -1\n",
    "for seed in range(100):\n",
    "    tf.random.set_seed(seed=seed)\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(nNeurons, activation='relu', input_shape=(nDaysMin, nFeatures)))\n",
    "    model.add(Dense(1))\n",
    "    opt = Adam(learning_rate=0.1)\n",
    "    model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(XTrain, yTrain[:,0], epochs=1000, verbose=0)\n",
    "\n",
    "    yPredListList = []\n",
    "    for day in range(nTest):\n",
    "        yPredListList.append([])\n",
    "    XValidNew = XValid.copy()\n",
    "    for day in range(k):\n",
    "        yPred = model.predict(np.float32(XValidNew), verbose=0)\n",
    "        for i in range(len(yPred)):\n",
    "            yPredListList[i].append(yPred[i][0])\n",
    "        XValidNew = np.delete(XValidNew, 0, axis=1)\n",
    "        yPred = np.expand_dims(yPred, 2)\n",
    "        XValidNew = np.append(XValidNew, yPred, axis=1)\n",
    "\n",
    "#     for yTrue, yPred in zip(yTest, yPredList):\n",
    "#         print(yTrue, yPred)\n",
    "    MAPE = meanAbsolutePercentageError_kDay(yValid, yPredListList)\n",
    "    print(seed, MAPE)\n",
    "    if MAPE < bestValidMAPE:\n",
    "        print('Updating best MAPE to {}...'.format(MAPE))\n",
    "        bestValidMAPE = MAPE\n",
    "        print('Updating best seed to {}...'.format(seed))\n",
    "        bestSeed = seed\n",
    "\n",
    "# define model\n",
    "print('Training model with best seed...')\n",
    "tf.random.set_seed(seed=bestSeed)\n",
    "\n",
    "#model = Sequential()\n",
    "model.add(LSTM(nNeurons, activation='relu', input_shape=(nDaysMin, nFeatures)))\n",
    "model.add(Dense(1))\n",
    "opt = Adam(learning_rate=0.1)\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "# fit model\n",
    "history = model.fit(XTrain, yTrain[:,0], validation_data = (XValid, yValid), epochs=1000, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredListList = []\n",
    "for day in range(nTest):\n",
    "    yPredListList.append([])\n",
    "XTestNew = XTest.copy()\n",
    "for day in range(k):\n",
    "    yPred = model.predict(np.float32(XTestNew), verbose=0)\n",
    "    for i in range(len(yPred)):\n",
    "        yPredListList[i].append(yPred[i][0])\n",
    "    XTestNew = np.delete(XTestNew, 0, axis=1)\n",
    "    yPred = np.expand_dims(yPred, 2)\n",
    "    XTestNew = np.append(XTestNew, yPred, axis=1)\n",
    "MAPE = meanAbsolutePercentageError_kDay(yTest, yPredListList)\n",
    "print('Test MAPE:', MAPE)\n",
    "MdSA = medianSymmetricAccuracy_kDay(yTest, yPredListList)\n",
    "print('Test MdSA:', MdSA)\n",
    "MSE = meanSquaredError(yTest, yPredList)\n",
    "print('Test MSE:', MSE)\n",
    "RMSE = rootMeanSquaredError(yTest, yPredList)\n",
    "print('Test RMSE:', RMSE)\n",
    "yPredVanilla = yPredListList    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nNeurons = 50\n",
    "nFeatures = 1\n",
    "\n",
    "bestValidMAPE = 100\n",
    "bestSeed = -1\n",
    "for seed in range(100):\n",
    "    tf.random.set_seed(seed=seed)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(nNeurons, activation='relu', return_sequences=True, input_shape=(nDaysMin, nFeatures)))\n",
    "    model.add(LSTM(nNeurons, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    opt = Adam(learning_rate=0.1)\n",
    "    model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "    # fit model\n",
    "    model.fit(XTrain, yTrain[:,0], epochs=1000, verbose=0)\n",
    "\n",
    "    yPredListList = []\n",
    "    for day in range(nTest):\n",
    "        yPredListList.append([])\n",
    "    XValidNew = XValid.copy()\n",
    "    for day in range(k):\n",
    "        yPred = model.predict(np.float32(XValidNew), verbose=0)\n",
    "        for i in range(len(yPred)):\n",
    "            yPredListList[i].append(yPred[i][0])\n",
    "        XValidNew = np.delete(XValidNew, 0, axis=1)\n",
    "        yPred = np.expand_dims(yPred, 2)\n",
    "        XValidNew = np.append(XValidNew, yPred, axis=1)\n",
    "\n",
    "#     for yTrue, yPred in zip(yTest, yPredList):\n",
    "#         print(yTrue, yPred)\n",
    "\n",
    "    MAPE = meanAbsolutePercentageError_kDay(yValid, yPredListList)\n",
    "    print(seed, MAPE)\n",
    "    if MAPE < bestValidMAPE:\n",
    "        print('Updating best MAPE to {}...'.format(MAPE))\n",
    "        bestValidMAPE = MAPE\n",
    "        print('Updating best seed to {}...'.format(seed))\n",
    "        bestSeed = seed\n",
    "        \n",
    "# define model\n",
    "print('Training model with best seed...')\n",
    "tf.random.set_seed(seed=bestSeed)\n",
    "model = Sequential()\n",
    "model.add(LSTM(nNeurons, activation='relu', return_sequences=True, input_shape=(nDaysMin, nFeatures)))\n",
    "model.add(LSTM(nNeurons, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "opt = Adam(learning_rate=0.1)\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "model.summary()\n",
    "\n",
    "# fit model\n",
    "history = model.fit(XTrain, yTrain[:,0], validation_data = (XValid, yValid), epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredListList = []\n",
    "for day in range(nTest):\n",
    "    yPredListList.append([])\n",
    "XTestNew = XTest.copy()\n",
    "for day in range(k):\n",
    "    yPred = model.predict(np.float32(XTestNew), verbose=0)\n",
    "    for i in range(len(yPred)):\n",
    "        yPredListList[i].append(yPred[i][0])\n",
    "    XTestNew = np.delete(XTestNew, 0, axis=1)\n",
    "    yPred = np.expand_dims(yPred, 2)\n",
    "    XTestNew = np.append(XTestNew, yPred, axis=1)\n",
    "    \n",
    "MAPE = meanAbsolutePercentageError_kDay(yTest, yPredListList)\n",
    "print('Test MAPE:', MAPE)\n",
    "MdSA = medianSymmetricAccuracy_kDay(yTest, yPredListList)\n",
    "print('Test MdSA:', MdSA)\n",
    "MSE = meanSquaredError(yTest, yPredListList)\n",
    "print('Test MSE:', MSE)\n",
    "RMSE = rootMeanSquaredError(yTest, yPredListList)\n",
    "print('Test RMSE:', RMSE)\n",
    "yPredStacked = yPredListList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "nNeurons = 50\n",
    "nFeatures = 1\n",
    "\n",
    "bestValidMAPE = 100\n",
    "bestSeed = -1\n",
    "for seed in range(100):\n",
    "    tf.random.set_seed(seed=seed)\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(nNeurons, activation='relu'), input_shape=(nDaysMin, nFeatures)))\n",
    "    model.add(Dense(1))\n",
    "    opt = Adam(learning_rate=0.1)\n",
    "    model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(XTrain, yTrain[:,0], epochs=1000, verbose=0)\n",
    "\n",
    "    yPredListList = []\n",
    "    for day in range(nTest):\n",
    "        yPredListList.append([])\n",
    "    XValidNew = XValid.copy()\n",
    "    for day in range(k):\n",
    "        yPred = model.predict(np.float32(XValidNew), verbose=0)\n",
    "        for i in range(len(yPred)):\n",
    "            yPredListList[i].append(yPred[i][0])\n",
    "        XValidNew = np.delete(XValidNew, 0, axis=1)\n",
    "        yPred = np.expand_dims(yPred, 2)\n",
    "        XValidNew = np.append(XValidNew, yPred, axis=1)\n",
    "\n",
    "#     for yTrue, yPred in zip(yTest, yPredList):\n",
    "#         print(yTrue, yPred)\n",
    "    MAPE = meanAbsolutePercentageError_kDay(yValid, yPredListList)\n",
    "    print(seed, MAPE)\n",
    "    if MAPE < bestValidMAPE:\n",
    "        print('Updating best MAPE to {}...'.format(MAPE))\n",
    "        bestValidMAPE = MAPE\n",
    "        print('Updating best seed to {}...'.format(seed))\n",
    "        bestSeed = seed\n",
    "# define model\n",
    "print('Training model with best seed...')\n",
    "tf.random.set_seed(seed=bestSeed)\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(nNeurons, activation='relu'), input_shape=(nDaysMin, nFeatures)))\n",
    "model.add(Dense(1))\n",
    "opt = Adam(learning_rate=0.1)\n",
    "model.compile(optimizer=opt, loss='mse')\n",
    "model.summary()\n",
    "\n",
    "# fit model\n",
    "history = model.fit(XTrain, yTrain[:,0], validation_data = (XValid, yValid), epochs=1000, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredListList = []\n",
    "for day in range(nTest):\n",
    "    yPredListList.append([])\n",
    "XTestNew = XTest.copy()\n",
    "for day in range(k):\n",
    "    yPred = model.predict(np.float32(XTestNew), verbose=0)\n",
    "    for i in range(len(yPred)):\n",
    "        yPredListList[i].append(yPred[i][0])\n",
    "    XTestNew = np.delete(XTestNew, 0, axis=1)\n",
    "    yPred = np.expand_dims(yPred, 2)\n",
    "    XTestNew = np.append(XTestNew, yPred, axis=1)\n",
    "    \n",
    "MAPE = meanAbsolutePercentageError_kDay(yTest, yPredListList)\n",
    "print('Test MAPE:', MAPE)\n",
    "MdSA = medianSymmetricAccuracy_kDay(yTest, yPredListList)\n",
    "print('Test MdSA:', MdSA)\n",
    "MSE = meanSquaredError(yTest, yPredListList)\n",
    "print('Test MSE:', MSE)\n",
    "RMSE = rootMeanSquaredError(yTest, yPredListList)\n",
    "print('Test RMSE:', RMSE)\n",
    "yPredBidirectional = yPredListList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib.dates import DateFormatter\n",
    "#from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Format y tick labels\n",
    "def y_fmt(y, pos):\n",
    "    decades = [1e9, 1e6, 1e3, 1e0, 1e-3, 1e-6, 1e-9 ]\n",
    "    suffix  = [\"G\", \"M\", \"k\", \"\" , \"m\" , \"u\", \"n\"  ]\n",
    "    if y == 0:\n",
    "        return str(0)\n",
    "    for i, d in enumerate(decades):\n",
    "        if np.abs(y) >=d:\n",
    "            val = y/float(d)\n",
    "            signf = len(str(val).split(\".\")[1])\n",
    "            if signf == 0:\n",
    "                return '{val:d} {suffix}'.format(val=int(val), suffix=suffix[i])\n",
    "            else:\n",
    "                if signf == 1:\n",
    "                    if str(val).split(\".\")[1] == \"0\":\n",
    "                        return '{val:d} {suffix}'.format(val=int(round(val)), suffix=suffix[i]) \n",
    "                tx = \"{\"+\"val:.{signf}f\".format(signf = signf) +\"} {suffix}\"\n",
    "                return tx.format(val=val, suffix=suffix[i])\n",
    "\n",
    "                #return y\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "datesForPlottingList = datesGreaterDaysSinceList[-k:]\n",
    "groundTruthList = nCasesGreaterDaysSinceList[-k:]\n",
    "\n",
    "\n",
    "plt.ylabel('Number of confirmed cases for Russia', fontsize=20)\n",
    "plt.plot(datesForPlottingList, groundTruthList, '-o', linewidth=3, label='Actual confirmed numbers');\n",
    "plt.plot(datesForPlottingList, yPredVanilla[-1], '-o', linewidth=3, label='Vanilla LSTM predictions');\n",
    "plt.plot(datesForPlottingList, yPredStacked[-1], '-o', linewidth=3, label='Stacked LSTM predictions');\n",
    "plt.plot(datesForPlottingList, yPredBidirectional[-1], '-o', linewidth=3, label='Bidirectional LSTM predictions');\n",
    "plt.xlabel('Date', fontsize=20);\n",
    "plt.legend(fontsize=14);\n",
    "plt.xticks(fontsize=16);\n",
    "plt.yticks(fontsize=16);\n",
    "ax = plt.gca()\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(y_fmt))\n",
    "#date_form = DateFormatter(\"%d-%m\")\n",
    "#ax.xaxis.set_major_formatter(date_form)\n",
    "# plt.grid(axis='y')\n",
    "plt.savefig(os.path.join('Plots_10days_k7', 'predictions_{}.png'.format(countryName)), dpi=400)\n",
    "plt.savefig(os.path.join('Plots_10days_k7', 'predictions_{}.pdf'.format(countryName)), dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datesForPlottingList\n",
    "groundTruthList\n",
    "yPredVanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datesForPlottingList\n",
    "groundTruthList\n",
    "yPredVanilla\n",
    "allvalues = {\n",
    "    'Date': ['7/22/20', '7/23/20', '7/24/20', '7/25/20', '7/26/20', '7/27/20', '7/28/20'],\n",
    "    'Actual':,\n",
    "    'Predicted_Vanilla': ,\n",
    "    'Predicted_Stacked': ,\n",
    "    'Predicted_BiLSTM' : }\n",
    "\n",
    "print(allvalues)\n",
    "allvalues = pd.to_csv ('russia_10d_k7_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
